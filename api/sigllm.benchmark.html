
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>sigllm.benchmark module &#8212; sigllm 0.1.1.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="shortcut icon" href="../_static/dai-logo-white.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="sigllm.core module" href="sigllm.core.html" />
    <link rel="prev" title="sigllm.primitives.transformation module" href="sigllm.primitives.transformation.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <img src="../_static/dai-logo-white-200.png" class="logo" alt="logo" />
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../readme.html">SigLLM</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="sigllm.html">API Reference</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../contributing.html">Contributing</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../authors.html">Credits</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../history.html">History</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/sintel-dev/sigllm" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
        
        
        
        
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="module-sigllm.benchmark">
<span id="sigllm-benchmark-module"></span><h1>sigllm.benchmark module<a class="headerlink" href="#module-sigllm.benchmark" title="Permalink to this headline">¶</a></h1>
<dl class="py function">
<dt id="sigllm.benchmark.benchmark">
<code class="sig-prename descclassname">sigllm.benchmark.</code><code class="sig-name descname">benchmark</code><span class="sig-paren">(</span><em class="sig-param">pipelines=None</em>, <em class="sig-param">datasets=None</em>, <em class="sig-param">hyperparameters=None</em>, <em class="sig-param">metrics={'accuracy': &lt;function contextual_accuracy&gt;</em>, <em class="sig-param">'f1': &lt;function contextual_f1_score&gt;</em>, <em class="sig-param">'precision': &lt;function contextual_precision&gt;</em>, <em class="sig-param">'recall': &lt;function contextual_recall&gt;}</em>, <em class="sig-param">rank='f1'</em>, <em class="sig-param">test_split=False</em>, <em class="sig-param">iterations=1</em>, <em class="sig-param">workers=1</em>, <em class="sig-param">show_progress=False</em>, <em class="sig-param">cache_dir=None</em>, <em class="sig-param">anomaly_dir=None</em>, <em class="sig-param">resume=False</em>, <em class="sig-param">output_path=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/sigllm/benchmark.html#benchmark"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sigllm.benchmark.benchmark" title="Permalink to this definition">¶</a></dt>
<dd><p>Run pipelines on the given datasets and evaluate the performance.</p>
<p>The pipelines are used to analyze the given signals and later on the
detected anomalies are scored against the known anomalies using the
indicated metrics.</p>
<p>Finally, the scores obtained with each metric are averaged accross all the signals,
ranked by the indicated metric and returned on a <code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pipelines</strong> (<em>dict</em><em> or </em><em>list</em>) – dictionary with pipeline names as keys and their
JSON paths as values. If a list is given, it should be of JSON paths,
and the paths themselves will be used as names. If not give, all verified
pipelines will be used for evaluation.</p></li>
<li><p><strong>datasets</strong> (<em>dict</em><em> or </em><em>list</em>) – dictionary of dataset name as keys and list of signals as
values. If a list is given then it will be under a generic name <code class="docutils literal notranslate"><span class="pre">dataset</span></code>.
If not given, all benchmark datasets will be used used.</p></li>
<li><p><strong>hyperparameters</strong> (<em>dict</em><em> or </em><em>list</em>) – dictionary with pipeline names as keys
and their hyperparameter JSON paths or dictionaries as values. If a list is
given, it should be of corresponding order to pipelines.</p></li>
<li><p><strong>metrics</strong> (<em>dict</em><em> or </em><em>list</em>) – dictionary with metric names as keys and
scoring functions as values. If a list is given, it should be of scoring
functions, and they <code class="docutils literal notranslate"><span class="pre">__name__</span></code> value will be used as the metric name.
If not given, all the available metrics will be used.</p></li>
<li><p><strong>rank</strong> (<em>str</em>) – Sort and rank the pipelines based on the given metric.
If not given, rank using the first metric.</p></li>
<li><p><strong>test_split</strong> (<em>bool</em><em> or </em><em>float</em>) – Whether to use the prespecified train-test split. If
float, then it should be between 0.0 and 1.0 and represent the proportion of
the signal to include in the test split. If not given, use <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>iterations</strong> (<em>int</em>) – Number of iterations to perform over each signal and pipeline. Defaults to 1.</p></li>
<li><p><strong>workers</strong> (<em>int</em>) – If <code class="docutils literal notranslate"><span class="pre">workers</span></code> is given as an integer value other than 0 or 1, a multiprocessing
Pool is used to distribute the computation across the indicated number of workers.</p></li>
<li><p><strong>show_progress</strong> (<em>bool</em>) – Whether to use tqdm to keep track of the progress. Defaults to <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><strong>cache_dir</strong> (<em>str</em>) – If a <code class="docutils literal notranslate"><span class="pre">cache_dir</span></code> is given, intermediate results are stored in the indicated directory
as CSV files as they get computted. This allows inspecting results while the benchmark
is still running and also recovering results in case the process does not finish
properly. Defaults to <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>anomaly_dir</strong> (<em>str</em>) – If a <code class="docutils literal notranslate"><span class="pre">anomaly_dir</span></code> is given, detected anomalies will get dumped in the specificed
directory as csv files. Defaults to <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>resume</strong> (<em>bool</em>) – Whether to continue running the experiments in the benchmark from the current
progress in <code class="docutils literal notranslate"><span class="pre">cache_dir</span></code>.</p></li>
<li><p><strong>output_path</strong> (<em>str</em>) – Location to save the intermediatry results. If not given,
intermediatry results will not be saved.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A table containing the scores obtained with each scoring function accross
all the signals for each pipeline.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="sigllm.benchmark.main">
<code class="sig-prename descclassname">sigllm.benchmark.</code><code class="sig-name descname">main</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">pipelines</span></em>, <em class="sig-param"><span class="n">datasets</span></em>, <em class="sig-param"><span class="n">resume</span></em>, <em class="sig-param"><span class="n">workers</span></em>, <em class="sig-param"><span class="n">output_path</span></em>, <em class="sig-param"><span class="n">cache_dir</span></em>, <em class="sig-param"><span class="n">anomaly_dir</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/sigllm/benchmark.html#main"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sigllm.benchmark.main" title="Permalink to this definition">¶</a></dt>
<dd><p>Main to call benchmark function.</p>
</dd></dl>

</section>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="sigllm.primitives.transformation.html" title="previous page">sigllm.primitives.transformation module</a>
    <a class='right-next' id="next-link" href="sigllm.core.html" title="next page">sigllm.core module</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2023, MIT Data To AI Lab.<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.2.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>