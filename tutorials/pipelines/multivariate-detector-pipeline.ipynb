{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multivariate Pipeline Tutorial\n",
        "\n",
        "This notebook demonstrates how to use the multivariate detector pipeline with different formatting methods for multidimensional time series data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sigllm.primitives.formatting import (\n",
        "    JSONFormat,\n",
        "    UnivariateControl,\n",
        "    PersistenceControl,\n",
        "    ValueConcatenation,\n",
        "    ValueInterleave,\n",
        "    DigitInterleave,\n",
        "    utils\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Sample Multivariate Data\n",
        "\n",
        "First, let's create some sample multivariate time series data with 3 dimensions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   timestamp    x1  x2    x3\n",
            "0        0.0  0.10   0  0.65\n",
            "1     3600.0  0.11   1  0.64\n",
            "2     7200.0  0.12   0  0.63\n",
            "3    10800.0  0.13   1  0.62\n",
            "4    14400.0  0.14   0  0.61\n",
            "Sample data shape: (10, 15, 3)\n"
          ]
        }
      ],
      "source": [
        "# Create sample data with 3 dimensions\n",
        "N = 25\n",
        "raw_data = utils.create_test_data()\n",
        "print(raw_data.head())\n",
        "\n",
        "raw_data = raw_data.to_numpy()[:, 1:]\n",
        "windowed_data = np.array([raw_data[i:i+15,:] for i in range(0, len(raw_data)-15, 1)])\n",
        "data = (1000 * windowed_data).astype(int)\n",
        "\n",
        "print(\"Sample data shape:\", data.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Available Formatting Methods\n",
        "\n",
        "The multivariate pipeline supports several formatting methods to convert multi-dimensional data into string representations for LLM processing:\n",
        "\n",
        "1. **JSONFormat**: Formats as d0:val,d1:val,... per timestamp\n",
        "2. **ValueConcatenation**: Flattens all dimensions per timestamp\n",
        "3. **ValueInterleave**: Interleaves values with zero-padding\n",
        "4. **DigitInterleave**: Interleaves individual digits\n",
        "5. **UnivariateControl**: Uses only first dimension (baseline)\n",
        "6. **PersistenceControl**: Returns last value (naive baseline)\n",
        "\n",
        "\n",
        "For example, given timesteps $t_0$ = [50, 30, 100] and $t_1$ = [55, 28, 104]:\n",
        "* Value Concatenation - Simply flatten the values across time: 50,30,100,55,28,104\n",
        "* Value Interleave - Pad values to equal digit length and concatenate timestep by timestep: 050030100,055028104\n",
        "* Digit Interleave - Interleave digits positionally across dimensions: 001530000,001520584\n",
        "* JSON Format - Encode as dimension-labeled key:value pairs: d0:50,d1:30,d2:100,d0:55,d1:28,d2:104\n",
        "* Univariate Control - Keep only one dimension (baseline for comparison): 50,55\n",
        "* Persistence Control - Bypass the formatting and return last known value: N/A\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation suite passed\n",
            "Validation suite passed\n",
            "Validation suite passed\n",
            "Validation suite passed\n",
            "Validation suite passed\n"
          ]
        }
      ],
      "source": [
        "# Compare string representations from different methods\n",
        "methods = {\n",
        "    'JSONFormat': JSONFormat(),\n",
        "    'ValueConcatenation': ValueConcatenation(),\n",
        "    'ValueInterleave': ValueInterleave(),\n",
        "    'DigitInterleave': DigitInterleave(),\n",
        "    'UnivariateControl': UnivariateControl(),\n",
        "    'PersistenceControl': PersistenceControl(),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparison of formatting methods on the same data:\n",
            "\n",
            "JSONFormat:\n",
            "\td0:100,d1:0,d2:650,d0:110,d1:1000,d2:640,d0:120,d1:0,d2:630,d0:130,d1:1000,d2:62...\n",
            "\n",
            "ValueConcatenation:\n",
            "\t100,0,650,110,1000,640,120,0,630,130,1000,620,140,0,610,150,1000,600,160,0,590,1...\n",
            "\n",
            "ValueInterleave:\n",
            "\t010000000650,011010000640,012000000630,013010000620,014000000610,015010000600,01...\n",
            "\n",
            "DigitInterleave:\n",
            "\t000106005000,010106104000,000106203000,010106302000,000106401000,010106500000,00...\n",
            "\n",
            "UnivariateControl:\n",
            "\t100,110,120,130,140,150,160,170,180,190,200,210,220,230,240...\n",
            "\n",
            "PersistenceControl:\n",
            "\t100,110,120,130,140,150,160,170,180,190,200,210,220,230,240...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Comparison of formatting methods on the same data:\\n\")\n",
        "\n",
        "\n",
        "\n",
        "for name, method in methods.items():\n",
        "    try:\n",
        "        print(f\"{name}:\")\n",
        "        output = method.format_as_string(data)\n",
        "        print(f\"\\t{output[0][:80]}...\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"{name}: Error - {e}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deep dive into JSONFormat\n",
        "\n",
        "In this section, we show an end-to-end use of the multivariate detector pipeline on "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation suite passed\n",
            "Validation suite passed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/baranov/miniconda/envs/orion310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2026-02-09 02:51:38.434721: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-02-09 02:51:38.468218: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2026-02-09 02:51:38.468252: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2026-02-09 02:51:38.468287: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2026-02-09 02:51:38.475691: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2026-02-09 02:51:39.151569: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.55s/it]\n",
            "Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.55s/it]\n",
            "100%|██████████| 10/10 [00:10<00:00,  1.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Residual: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sigllm.primitives.formatting.utils import test_multivariate_formatting_validity, run_pipeline\n",
        "\n",
        "method = JSONFormat()\n",
        "test_multivariate_formatting_validity(method)\n",
        "errors, y_hat, y = run_pipeline(method, multivariate_allowed_symbols=[\"d\", \":\", \",\"], verbose=False)\n",
        "print(f\"Mean Residual: {np.mean(errors)}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "orion310",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
